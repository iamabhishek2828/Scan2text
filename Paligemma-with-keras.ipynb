{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"name":"inference-with-keras.ipynb","toc_visible":true},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9386853,"sourceType":"datasetVersion","datasetId":5695494},{"sourceId":9393162,"sourceType":"datasetVersion","datasetId":5700478},{"sourceId":9394932,"sourceType":"datasetVersion","datasetId":5701816},{"sourceId":52890,"sourceType":"modelInstanceVersion","modelInstanceId":44362,"modelId":52393},{"sourceId":110653,"sourceType":"modelInstanceVersion","modelInstanceId":44362,"modelId":52393}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U keras-nlp\n!pip install -q -U keras>=3","metadata":{"id":"DoYMMytAaMRJ","_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-09-15T16:14:47.624397Z","iopub.execute_input":"2024-09-15T16:14:47.624771Z","iopub.status.idle":"2024-09-15T16:15:17.560978Z","shell.execute_reply.started":"2024-09-15T16:14:47.624729Z","shell.execute_reply":"2024-09-15T16:15:17.559682Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport keras\nimport keras_nlp\nimport numpy as np\nimport PIL\nimport requests\nimport io\nimport matplotlib\nimport re\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom PIL import Image\n\nos.environ[\"KERAS_BACKEND\"] = \"jax\"\nkeras.config.set_floatx(\"bfloat16\")","metadata":{"id":"MHECpBe6LE7y","_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-09-15T16:15:17.562902Z","iopub.execute_input":"2024-09-15T16:15:17.563234Z","iopub.status.idle":"2024-09-15T16:15:30.697800Z","shell.execute_reply.started":"2024-09-15T16:15:17.563201Z","shell.execute_reply":"2024-09-15T16:15:30.697019Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"paligemma = keras_nlp.models.PaliGemmaCausalLM.from_preset(\"pali_gemma_3b_mix_224\")\npaligemma.summary()","metadata":{"id":"abNuIP8D_9At","_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-09-15T16:15:30.698892Z","iopub.execute_input":"2024-09-15T16:15:30.699414Z","iopub.status.idle":"2024-09-15T16:16:39.237353Z","shell.execute_reply.started":"2024-09-15T16:15:30.699379Z","shell.execute_reply":"2024-09-15T16:16:39.236437Z"},"trusted":true},"outputs":[{"name":"stderr","text":"normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"pali_gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"pali_gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ pali_gemma_tokenizer (\u001b[38;5;33mPaliGemmaTokenizer\u001b[0m)                     │                      Vocab size: \u001b[38;5;34m257,152\u001b[0m │\n├───────────────────────────────────────────────────────────────┼──────────────────────────────────────────┤\n│ pali_gemma_image_converter (\u001b[38;5;33mPaliGemmaImageConverter\u001b[0m)          │                   Image size: (\u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m) │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ pali_gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PaliGemmaTokenizer</span>)                     │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">257,152</span> │\n├───────────────────────────────────────────────────────────────┼──────────────────────────────────────────┤\n│ pali_gemma_image_converter (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PaliGemmaImageConverter</span>)          │                   Image size: (<span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>) │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"pali_gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"pali_gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ images (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ response_mask (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ pali_gemma_backbone           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,923,335,408\u001b[0m │ images[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],              │\n│ (\u001b[38;5;33mPaliGemmaBackbone\u001b[0m)           │                           │                 │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│                               │                           │                 │ response_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m257152\u001b[0m)      │     \u001b[38;5;34m526,647,296\u001b[0m │ pali_gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ get_item (\u001b[38;5;33mGetItem\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m257152\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │ token_embedding[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ images (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ response_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ pali_gemma_backbone           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,923,335,408</span> │ images[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],              │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PaliGemmaBackbone</span>)           │                           │                 │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│                               │                           │                 │ response_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">257152</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">526,647,296</span> │ pali_gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">257152</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ token_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,923,335,408\u001b[0m (5.45 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,923,335,408</span> (5.45 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,923,335,408\u001b[0m (5.45 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,923,335,408</span> (5.45 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nimport PIL\nimport os\n\n# Define crop_and_resize function to crop and resize an image\ndef crop_and_resize(image, target_size):\n    \"\"\"Crops the image from the center and resizes it to the target size.\"\"\"\n    width, height = image.size\n    source_size = min(image.size)\n    left = width // 2 - source_size // 2\n    top = height // 2 - source_size // 2\n    right, bottom = left + source_size, top + source_size\n    return image.crop((left, top, right, bottom)).resize(target_size)\n\n# Define read_image function to load, crop, and resize images from the local path\nimport PIL\nimport numpy as np\n\ndef read_image(image_path, target_size):\n    \"\"\"Reads the image from a local path, crops and resizes it to the target size, and ensures it's in RGB format.\"\"\"\n    # Open the image using PIL\n    image = PIL.Image.open(image_path)\n    \n    # Convert the image to RGB if it's grayscale (L mode)\n    if image.mode == 'L':  # L mode means it's a grayscale image\n        image = image.convert('RGB')  # Convert grayscale to RGB\n    \n    # Crop and resize the image using your custom crop_and_resize function\n    image = crop_and_resize(image, target_size)\n    \n    # Convert the image to a NumPy array\n    image = np.array(image)\n    \n    # Remove alpha channel if present (RGBA images)\n    if image.shape[2] == 4:  # If the image has 4 channels (RGBA), remove the alpha channel\n        image = image[:, :, :3]  # Keep only the first 3 channels (RGB)\n    \n    return image\n\n\ndef parse_bbox_and_labels(detokenized_output: str):\n  matches = re.finditer(\n      '<loc(?P<y0>\\d\\d\\d\\d)><loc(?P<x0>\\d\\d\\d\\d)><loc(?P<y1>\\d\\d\\d\\d)><loc(?P<x1>\\d\\d\\d\\d)>'\n      ' (?P<label>.+?)( ;|$)',\n      detokenized_output,\n  )\n  labels, boxes = [], []\n  fmt = lambda x: float(x) / 1024.0\n  for m in matches:\n    d = m.groupdict()\n    boxes.append([fmt(d['y0']), fmt(d['x0']), fmt(d['y1']), fmt(d['x1'])])\n    labels.append(d['label'])\n  return np.array(boxes), np.array(labels)\n\ndef display_boxes(image, boxes, labels, target_image_size):\n  h, l = target_size\n  fig, ax = plt.subplots()\n  ax.imshow(image)\n  for i in range(boxes.shape[0]):\n      y, x, y2, x2 = (boxes[i]*h)\n      width = x2 - x\n      height = y2 - y\n      # Create a Rectangle patch\n      rect = patches.Rectangle((x, y),\n                               width,\n                               height,\n                               linewidth=1,\n                               edgecolor='r',\n                               facecolor='none')\n      # Add label\n      plt.text(x, y, labels[i], color='red', fontsize=12)\n      # Add the patch to the Axes\n      ax.add_patch(rect)\n\n  plt.show()\n\ndef display_segment_output(image, segment_mask, target_image_size):\n  # Calculate scaling factors\n  h, w = target_image_size\n  x_scale = w / 64\n  y_scale = h / 64\n\n  # Create coordinate grids for the new image\n  x_coords = np.arange(w)\n  y_coords = np.arange(h)\n  x_coords = (x_coords / x_scale).astype(int)\n  y_coords = (y_coords / y_scale).astype(int)\n  resized_array = segment_mask[y_coords[:, np.newaxis], x_coords]\n  # Create a figure and axis\n  fig, ax = plt.subplots()\n\n  # Display the image\n  ax.imshow(image)\n\n  # Overlay the mask with transparency\n  ax.imshow(resized_array, cmap='jet', alpha=0.5)","metadata":{"id":"S6_XQjhpvXiG","execution":{"iopub.status.busy":"2024-09-15T16:16:39.239435Z","iopub.execute_input":"2024-09-15T16:16:39.239721Z","iopub.status.idle":"2024-09-15T16:16:39.256453Z","shell.execute_reply.started":"2024-09-15T16:16:39.239690Z","shell.execute_reply":"2024-09-15T16:16:39.255711Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport PIL\nimport os\nimport re  # Import regex for adding space between number and unit\nfrom tqdm import tqdm  # Import tqdm for the progress bar\n\n# Load your dataset (assuming it's a CSV file with image_path and entity_name columns)\ndf = pd.read_csv('/kaggle/input/resr-data/66e31d6ee96cd_student_resource_3/student_resource 3/dataset/test.csv')\ndf = df.head(1000)\n# Initialize an empty list to store the extracted entity values\nextracted_texts = []\n\n# Define target size for image resizing\ntarget_size = (224, 224)\n\nroot_folder = \"/kaggle/input/resr-data/test/test\"\n\n# Function to add a space between number and unit\ndef add_space_between_number_and_unit(text):\n    # This regular expression matches a number followed immediately by a letter (which is the unit).\n    return re.sub(r'(\\d)([a-zA-Z])', r'\\1 \\2', text)\n\n# Iterate through the dataset\nfor idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Extracting text\"):\n    image_link = row.get('image_link', '')  # Get the image link or an empty string if missing\n    entity_name = row['entity_name']\n    \n    # Check if the image link is valid (non-empty)\n    if not image_link or pd.isna(image_link):\n        extracted_texts.append('')  # Append an empty string for missing links\n        continue\n    \n    image_name = os.path.basename(image_link)  # Extract image name from the link\n    image_path = os.path.join(root_folder, image_name)\n    \n    # Check if the image file exists\n    if not os.path.exists(image_path):\n        extracted_texts.append('')  # Append an empty string if the image doesn't exist\n        continue\n    \n    # Load and preprocess the image using the read_image function\n    cow_image = read_image(image_path, target_size)\n    \n    # Create the prompt based on the entity_name\n    prompt = f'answer en what is the {entity_name} in the image?'\n    \n    # Generate output using PaLiGemma\n    output = paligemma.generate(\n        inputs={\n            \"images\": cow_image,\n            \"prompts\": prompt,\n        }\n    )\n    \n    # Remove the prompt and clean up the extracted entity value\n    entity_value = output.replace(prompt, '').strip()\n    \n    # Add space between number and unit\n    entity_value = add_space_between_number_and_unit(entity_value)\n    \n    # Append the cleaned and formatted entity_value to the list\n    extracted_texts.append(entity_value)\n\n# Add the extracted text as a new column in the DataFrameblur\ndf['entity_value'] = extracted_texts\n\n# Save the updated DataFrame to a new CSV file\ndf.to_csv('/kaggle/working/dataset_with_entity_values.csv', index=False)\n\n# Check the results\nprint(df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:18:10.518244Z","iopub.execute_input":"2024-09-15T16:18:10.518647Z","iopub.status.idle":"2024-09-15T17:04:43.690138Z","shell.execute_reply.started":"2024-09-15T16:18:10.518611Z","shell.execute_reply":"2024-09-15T17:04:43.689166Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Extracting text: 100%|██████████| 1000/1000 [46:32<00:00,  2.79s/it]","output_type":"stream"},{"name":"stdout","text":"   index                                         image_link  group_id  \\\n0      0  https://m.media-amazon.com/images/I/110EibNycl...    156839   \n1      1  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n2      2  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n3      3  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n4      4  https://m.media-amazon.com/images/I/11gHj8dhhr...    792578   \n\n  entity_name  entity_value  \n0      height        100 cm  \n1       width            54  \n2      height          5.54  \n3       depth  6.54 inches.  \n4       depth  4.13 inches.  \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":6}]}